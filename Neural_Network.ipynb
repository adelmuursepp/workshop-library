{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adelmuursepp/workshop-library/blob/main/Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Before you do anything...\n",
        "1. Make a copy of this notebook so that any progress is saved to your copy. If you \n",
        "don't make a copy, your changes will be gone the next time you try to access this notebook.\n",
        "2. Run the next cell to set up helper functions and examples. If you see strange errors of things not being defined, come back and run the set up cell again"
      ],
      "metadata": {
        "id": "BPl71sIjmHZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load libraries and data\n",
        "from sklearn.datasets import make_moons, make_circles, make_classification\n",
        "import pandas as pd\n",
        "import itertools\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly\n",
        "import plotly.io as pio\n",
        "import plotly.graph_objs as go\n",
        "pio.templates.default = \"simple_white\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "def visualize_model(model, X, labels, K=200):\n",
        "  x, y = X[:, 0], X[:, 1]\n",
        "  L = x.min() - 0.1\n",
        "  R = x.max() + 0.1\n",
        "  U = y.max() + 0.1\n",
        "  D = y.min() - 0.1\n",
        "\n",
        "  df = pd.DataFrame()\n",
        "\n",
        "  inputs = np.array( list( itertools.product(np.linspace(L,R, K), np.linspace(U,D, K))))\n",
        "  probs = model.predict(inputs, verbose=0).flatten()\n",
        "  pixels = np.zeros((K, K, 4))\n",
        "\n",
        "  pixels[:,:,:3] = np.transpose(\n",
        "          np.array(\n",
        "            [\n",
        "                plotly.colors.convert_to_RGB_255(p) for p in plotly.colors.sample_colorscale(\n",
        "                    plotly.colors.get_colorscale(\"Picnic\"), probs, 0, 1, \"tuple\"\n",
        "                  )\n",
        "            ]\n",
        "          ).reshape(K, K, 3)\n",
        "          ,[1,0,2] # Transpose\n",
        "  )\n",
        "  pixels[:,:,3] = 100 # Transparency\n",
        "\n",
        "  fig = px.imshow(pixels)\n",
        "  def x_to_px(x):\n",
        "    return (x - L) * (K-1) / (R - L)\n",
        "  \n",
        "  def y_to_py(y):\n",
        "    return (y-U) * (K-1) / (D - U)\n",
        "  \n",
        "  pixel_x = x_to_px(x)\n",
        "  pixel_y = y_to_py(y)\n",
        "  \n",
        "  preds = model.predict(X).flatten()\n",
        "  \n",
        "  MARKER_SIZE=10\n",
        "  fig.add_trace(\n",
        "      go.Scatter(x=pixel_x[np.where(labels==0)], y=pixel_y[np.where(labels==0)], marker={\"color\":\"blue\", \"size\":MARKER_SIZE}, mode=\"markers\", name=\"0\")\n",
        "  )\n",
        "  \n",
        "  fig.add_trace(\n",
        "      go.Scatter(x=pixel_x[np.where(labels==1)], y=pixel_y[np.where(labels==1)], marker={\"color\":\"red\", \"size\":MARKER_SIZE}, mode=\"markers\", name=\"1\")\n",
        "  )\n",
        "  fig.add_trace(\n",
        "      go.Scatter(x=pixel_x[labels != preds.round()], y=pixel_y[labels != preds.round()], marker={\"color\":\"white\", \"symbol\":\"x\", \"size\":MARKER_SIZE-3}, mode=\"markers\", name=\"errors\")\n",
        "  )\n",
        "  fig.show()\n",
        "\n",
        "X, labels = make_moons(noise=0.3, random_state=0)\n",
        "df = pd.DataFrame()\n",
        "\n",
        "df[\"x\"] = X[:,0]\n",
        "df[\"y\"] = X[:,1]\n",
        "df[\"label\"] = labels\n"
      ],
      "metadata": {
        "id": "FSqkhmXziebd",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot the data\n",
        "px.scatter(df, x=\"x\", y=\"y\", color=\"label\", height=700, width=700, color_continuous_scale=\"Picnic\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7F2hBK7osQbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building and Training the Neural Network\n",
        "\n",
        "The following implements a neural networks with two hidden layers. The first one has 16 neurons, and the second has 32. \n",
        "\n",
        "First, run the code as is to check that it works. Then, you can test your friends theory by removing the `activation = \"relu\"` optional arguments.\n",
        "\n",
        "You can also try adding more layers or changing the size of the layers by adding more lines like `layers.Dense(SIZE),`.\n",
        "\n",
        "Do not change the last layer!\n",
        "\n",
        "Run the cell to train your neural network on the data. You can visualize what you learned in the next cell."
      ],
      "metadata": {
        "id": "oaku_5Wtt81g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\", input_shape=[2]),\n",
        "    layers.Dense(32, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(X, labels, epochs=100)"
      ],
      "metadata": {
        "id": "edl1haKgYY2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's see how we did!\n",
        "\n",
        "Run the next cell to visualize the decision boundary of the model. The background color corresponds to the model's prediction at that location. The model learned well if the background colors match the placement of the datapoint (dots). The errors in the models predictions are marked by a white cross."
      ],
      "metadata": {
        "id": "c4cV9bsvXMWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_model(model, X, labels)"
      ],
      "metadata": {
        "id": "AH6tznBGZ9A3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, go back and test your friend's theory!"
      ],
      "metadata": {
        "id": "u29XYaq_lsDp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finding the equivalent single neuron neural network (optional)\n",
        "\n",
        "`model.layers` is a list of layers and `layer.get_weights` returns the weights and biases of a single layer. For example, the following code iterates over the layers.\n",
        "\n",
        "```\n",
        "for layer in model236.layers:\n",
        "  Wi, bi = layer.get_weights()\n",
        "  ...\n",
        "```\n",
        "\n",
        "Create a model with no activation functions (except for the last layer, which still must be sigmoid), and then find the equivalent single output neuron.\n",
        "\n",
        "You should compute the weights and bias of the output neuron and create a model like the following\n",
        "\n",
        "```\n",
        "model_equivalent = keras.Sequential([\n",
        "    layers.Dense(1, activation=\"sigmoid\", input_shape=[2])\n",
        "])\n",
        "\n",
        "model_equivalent.set_weights([COMPUTED_W, COMPUTED_b])\n",
        "```\n",
        "\n",
        "You can test if they are in fact equivalent by plotting their decision boundaries using `visualize_model`"
      ],
      "metadata": {
        "id": "0L9u4A61jlMl"
      }
    }
  ]
}